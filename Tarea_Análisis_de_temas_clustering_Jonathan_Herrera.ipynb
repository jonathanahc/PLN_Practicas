{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIy6SgO0LDKI/ahFZYyScE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathanahc/PLN_Practicas/blob/main/Tarea_An%C3%A1lisis_de_temas_clustering_Jonathan_Herrera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KlvAZV1_E_N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1b40ed-858e-469b-da15-8a1928ff02e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "from itertools import product\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    # Política\n",
        "    \"El presidente anunció nuevas reformas durante la conferencia en el Congreso.\",\n",
        "    \"Los partidos políticos debatieron sobre el futuro del sistema electoral.\",\n",
        "    \"La oposición critica la gestión gubernamental en materia de seguridad.\",\n",
        "    \"Miles de personas protestaron en la capital contra la nueva ley propuesta.\",\n",
        "    \"Se firmó un acuerdo internacional para fomentar la cooperación política.\",\n",
        "\n",
        "    # Economía\n",
        "    \"El banco central decidió aumentar las tasas de interés para controlar la inflación.\",\n",
        "    \"La economía del país creció un 3% durante el segundo trimestre del año.\",\n",
        "    \"Las exportaciones de productos agrícolas aumentaron notablemente.\",\n",
        "    \"El desempleo bajó por tercer mes consecutivo, según datos oficiales.\",\n",
        "    \"Los inversores mostraron confianza ante las nuevas políticas económicas.\",\n",
        "\n",
        "    # Deportes\n",
        "    \"La selección nacional clasificó a la final del campeonato continental.\",\n",
        "    \"El delantero estrella fue transferido al club europeo por una suma millonaria.\",\n",
        "    \"Los fanáticos celebraron la victoria con una caravana en las calles.\",\n",
        "    \"El equipo local perdió el partido decisivo por un gol en el último minuto.\",\n",
        "    \"La liga anunció cambios en el reglamento para la próxima temporada.\",\n",
        "\n",
        "    # Tecnología\n",
        "    \"La empresa lanzó un nuevo smartphone con inteligencia artificial integrada.\",\n",
        "    \"Se descubrió una vulnerabilidad crítica en el sistema operativo.\",\n",
        "    \"La inversión en energías renovables incluye avances en baterías inteligentes.\",\n",
        "    \"El uso de la automatización ha transformado la industria manufacturera.\",\n",
        "    \"Expertos debaten sobre los riesgos éticos del desarrollo de la IA.\",\n",
        "\n",
        "    # Medio ambiente\n",
        "    \"El cambio climático está afectando los patrones de lluvia en la región.\",\n",
        "    \"Un nuevo informe advierte sobre la pérdida acelerada de biodiversidad.\",\n",
        "    \"Se implementaron miles de políticas públicas para reducir las emisiones de carbono.\",\n",
        "    \"Miles de voluntarios participaron en una jornada de reforestación.\",\n",
        "    \"Organizaciones internacionales exigen medidas urgentes contra la contaminación.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "FwZZb9HDFMz7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('spanish'))\n",
        "texts = [\n",
        "    [word for word in word_tokenize(doc.lower()) if word.isalpha() and word not in stop_words]\n",
        "    for doc in documents\n",
        "]\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "zI0UipGmlsaa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lda(dictionary, corpus, texts, num_topics, alpha, eta, random_state=42):\n",
        "\n",
        "  model = LdaModel(\n",
        "      corpus=corpus,\n",
        "      id2word=dictionary,\n",
        "      num_topics=num_topics,\n",
        "      alpha=alpha,\n",
        "      eta=eta,\n",
        "      random_state=random_state,\n",
        "      chunksize=200,\n",
        "      passes=10,\n",
        "      iterations=200,\n",
        "      eval_every=None\n",
        "  )\n",
        "\n",
        "  log_perp = model.log_perplexity(corpus)\n",
        "\n",
        "  cm = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "  coh = cm.get_coherence()\n",
        "\n",
        "  return model, log_perp, coh\n",
        "\n",
        "topic_grid = [3, 5, 7, 9]\n",
        "alpha_grid = ['symmetric', 'asymmetric', 0.1, 0.3, 0.7]\n",
        "eta_grid   = ['symmetric', 0.01, 0.1]\n",
        "\n",
        "results = []\n",
        "best = {\"model\": None, \"coh\": -1e9}\n",
        "\n",
        "for k, a, b in product(topic_grid, alpha_grid, eta_grid):\n",
        "  model, logp, coh = train_lda(dictionary, corpus, texts, num_topics=k, alpha=a, eta=b)\n",
        "  results.append({\n",
        "      \"num_topics\": k,\n",
        "      \"alpha\": a,\n",
        "      \"beta(eta)\": b,\n",
        "      \"log_perplexity\": logp,\n",
        "      \"coherence_c_v\": coh\n",
        "    })\n",
        "  if coh > best[\"coh\"]:\n",
        "    best[\"coh\"] = coh\n",
        "    best[\"model\"] = model\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results).sort_values(\"coherence_c_v\", ascending=False).reset_index(drop=True)\n",
        "print(df_results.head(10))"
      ],
      "metadata": {
        "id": "5PG3iyFtFgDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e71bc4f-be90-459f-b338-0c2e52b5fbe9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   num_topics       alpha  beta(eta)  log_perplexity  coherence_c_v\n",
            "0           7  asymmetric       0.01       -7.781102       0.566554\n",
            "1           7  asymmetric        0.1       -6.253693       0.552234\n",
            "2           7  asymmetric  symmetric       -6.096206       0.528721\n",
            "3           3         0.3       0.01       -7.935901       0.520242\n",
            "4           3         0.3        0.1       -6.233678       0.520242\n",
            "5           3   symmetric       0.01       -7.949537       0.520242\n",
            "6           3   symmetric        0.1       -6.247217       0.520242\n",
            "7           3         0.1       0.01       -7.836755       0.507639\n",
            "8           9  asymmetric       0.01       -7.707841       0.507566\n",
            "9           3  asymmetric        0.1       -6.378564       0.500568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in best[\"model\"].print_topics():\n",
        "    print(f\"Tema {idx}: {topic}\")"
      ],
      "metadata": {
        "id": "DRGj-h5OkLfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3522d185-8861-43ee-9325-479c90d3283e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tema 0: 0.026*\"miles\" + 0.026*\"anunció\" + 0.026*\"nuevo\" + 0.013*\"políticas\" + 0.013*\"nuevas\" + 0.013*\"acelerada\" + 0.013*\"carbono\" + 0.013*\"suma\" + 0.013*\"club\" + 0.013*\"públicas\"\n",
            "Tema 1: 0.026*\"sistema\" + 0.026*\"partido\" + 0.026*\"equipo\" + 0.026*\"inflación\" + 0.026*\"interés\" + 0.026*\"gol\" + 0.026*\"último\" + 0.026*\"banco\" + 0.026*\"celebraron\" + 0.026*\"tasas\"\n",
            "Tema 2: 0.070*\"nueva\" + 0.070*\"personas\" + 0.070*\"capital\" + 0.070*\"exigen\" + 0.070*\"ley\" + 0.070*\"organizaciones\" + 0.070*\"protestaron\" + 0.070*\"urgentes\" + 0.070*\"propuesta\" + 0.070*\"contaminación\"\n",
            "Tema 3: 0.135*\"final\" + 0.135*\"campeonato\" + 0.135*\"selección\" + 0.135*\"continental\" + 0.135*\"nacional\" + 0.135*\"clasificó\" + 0.001*\"miles\" + 0.001*\"políticas\" + 0.001*\"nuevo\" + 0.001*\"voluntarios\"\n",
            "Tema 4: 0.065*\"según\" + 0.065*\"bajó\" + 0.065*\"datos\" + 0.065*\"partidos\" + 0.065*\"mes\" + 0.065*\"consecutivo\" + 0.065*\"oficiales\" + 0.065*\"políticos\" + 0.065*\"desempleo\" + 0.065*\"electoral\"\n",
            "Tema 5: 0.088*\"automatización\" + 0.088*\"manufacturera\" + 0.088*\"exportaciones\" + 0.088*\"uso\" + 0.088*\"transformado\" + 0.088*\"industria\" + 0.088*\"productos\" + 0.088*\"notablemente\" + 0.088*\"aumentaron\" + 0.088*\"agrícolas\"\n",
            "Tema 6: 0.007*\"miles\" + 0.007*\"nuevo\" + 0.007*\"voluntarios\" + 0.007*\"nuevas\" + 0.007*\"fanáticos\" + 0.007*\"políticas\" + 0.007*\"sistema\" + 0.007*\"aumentaron\" + 0.007*\"clasificó\" + 0.007*\"vulnerabilidad\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "vis = gensimvis.prepare(best[\"model\"], corpus, dictionary)\n",
        "\n",
        "pyLDAvis.save_html(vis, \"lda_best_vis.html\")\n",
        "\n",
        "print(\"Visualización guardada en lda_best_vis.html\")"
      ],
      "metadata": {
        "id": "384N8F6bFlf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bc1b08-3231-42de-d7a6-cc0b928a68a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualización guardada en lda_best_vis.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    }
  ]
}